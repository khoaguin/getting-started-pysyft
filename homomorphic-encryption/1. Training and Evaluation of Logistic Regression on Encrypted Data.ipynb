{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "import pandas as pd\n",
        "import random\n",
        "from time import time\n",
        "\n",
        "# those are optional and are not necessary for training\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(73)\n",
        "random.seed(73)\n",
        "\n",
        "\n",
        "def split_train_test(x, y, test_ratio=0.3):\n",
        "    idxs = [i for i in range(len(x))]\n",
        "    random.shuffle(idxs)\n",
        "    # delimiter between test and train data\n",
        "    delim = int(len(x) * test_ratio)\n",
        "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
        "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
        "\n",
        "\n",
        "def heart_disease_data():\n",
        "    data = pd.read_csv(\"./data/framingham.csv\")\n",
        "    # drop rows with missing values\n",
        "    data = data.dropna()\n",
        "    # drop some features\n",
        "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\", \"BMI\"])\n",
        "    # balance data\n",
        "    grouped = data.groupby('TenYearCHD')\n",
        "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
        "    # extract labels\n",
        "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
        "    data = data.drop(\"TenYearCHD\", 'columns')\n",
        "    # standardize data\n",
        "    data = (data - data.mean()) / data.std()\n",
        "    x = torch.tensor(data.values).float()\n",
        "    return split_train_test(x, y)\n",
        "\n",
        "# You can use whatever data you want without modification to the tutorial\n",
        "# x_train, y_train, x_test, y_test = random_data()\n",
        "x_train, y_train, x_test, y_test = heart_disease_data()\n",
        "\n",
        "print(\"############# Data summary #############\")\n",
        "print(f\"x_train has shape: {x_train.shape}\")\n",
        "print(f\"y_train has shape: {y_train.shape}\")\n",
        "print(f\"x_test has shape: {x_test.shape}\")\n",
        "print(f\"y_test has shape: {y_test.shape}\")\n",
        "print(\"#######################################\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "############# Data summary #############\nx_train has shape: torch.Size([780, 9])\ny_train has shape: torch.Size([780, 1])\nx_test has shape: torch.Size([334, 9])\ny_test has shape: torch.Size([334, 1])\n#######################################\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_2899/3852471796.py:25: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n  data = data.drop(\"TenYearCHD\", 'columns')\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127212195
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a normal Logistic Regression Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LR(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_features):\n",
        "        super(LR, self).__init__()\n",
        "        self.lr = torch.nn.Linear(n_features, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = torch.sigmoid(self.lr(x))\n",
        "        return out"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127545683
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = x_train.shape[1]\n",
        "model = LR(n_features)\n",
        "# use gradient descent with a learning_rate=1\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
        "# use Binary Cross Entropy Loss\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127573308
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the number of epochs for both plain and encrypted training\n",
        "EPOCHS = 5\n",
        "\n",
        "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
        "    for e in range(1, epochs + 1):\n",
        "        optim.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        print(f\"Loss at epoch {e}: {loss.data}\")\n",
        "    return model\n",
        "\n",
        "model = train(model, optim, criterion, x_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Loss at epoch 1: 0.8504331707954407\nLoss at epoch 2: 0.6863384246826172\nLoss at epoch 3: 0.6358115077018738\nLoss at epoch 4: 0.6193529367446899\nLoss at epoch 5: 0.6124349236488342\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127587223
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, x, y):\n",
        "    out = model(x)\n",
        "    correct = torch.abs(y - out) < 0.5\n",
        "    return correct.float().mean()\n",
        "\n",
        "plain_accuracy = accuracy(model, x_test, y_test)\n",
        "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy on plain test_set: 0.703592836856842\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127626259
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is worth to remember that a high accuracy isn't our goal. \n",
        "We just want to see that training on encrypted data doesn't affect the final result, \n",
        "so we will be comparing accuracies over encrypted data against the plain_accuracy \n",
        "we got here."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encrypted Evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we will just focus on evaluating the logistic regression model with \n",
        "plain parameters (optionally encrypted parameters) on the encrypted test set. \n",
        "We first create a PyTorch-like LR model that can evaluate encrypted data:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncryptedLR:\n",
        "    \n",
        "    def __init__(self, torch_lr):\n",
        "        # TenSEAL processes lists and not torch tensors,\n",
        "        # so we take out the parameters from the PyTorch model\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        \n",
        "    def forward(self, enc_x):\n",
        "        # We don't need to perform sigmoid as this model\n",
        "        # will only be used for evaluation, and the label\n",
        "        # can be deduced without applying sigmoid\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        return enc_out\n",
        "    \n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "        \n",
        "    ################################################\n",
        "    ## You can use the functions below to perform ##\n",
        "    ## the evaluation with an encrypted model     ##\n",
        "    ################################################\n",
        "    \n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "        \n",
        "    def decrypt(self, context):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "        \n",
        "\n",
        "eelr = EncryptedLR(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "syftenv",
      "language": "python",
      "display_name": "syft"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "syftenv"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}