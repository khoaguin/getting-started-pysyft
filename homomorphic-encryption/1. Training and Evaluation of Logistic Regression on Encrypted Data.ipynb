{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Training and Evaluation of Logistic Regression on Encrypted Data  \n",
        "[Source](https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "import torch\n",
        "import tenseal as ts\n",
        "import pandas as pd\n",
        "import random\n",
        "from time import time\n",
        "from icecream import ic\n",
        "\n",
        "# those are optional and are not necessary for training\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')"
      ],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632141101163
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "print(torch.__version__)\n",
        "print(ts.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.1+cu102\n",
            "0.3.5\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632140657642
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now prepare the training and test data. The dataset was downloaded from Kaggle [here](https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression). This dataset includes patients' information along with a 10-year risk of future coronary heart disease (CHD) as a label. The goal is to build a model that can predict this 10-year CHD risk based on patients' information. You can read more about the dataset in the link provided. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "torch.random.manual_seed(73)\n",
        "random.seed(73)\n",
        "\n",
        "\n",
        "def split_train_test(x, y, test_ratio=0.3):\n",
        "    idxs = [i for i in range(len(x))]\n",
        "    random.shuffle(idxs)\n",
        "    # delimiter between test and train data\n",
        "    delim = int(len(x) * test_ratio)\n",
        "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
        "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
        "\n",
        "\n",
        "def heart_disease_data():\n",
        "    data = pd.read_csv(\"./data/framingham.csv\")\n",
        "    # drop rows with missing values\n",
        "    data = data.dropna()\n",
        "    # drop some features\n",
        "    data = data.drop(columns=[\"education\", \"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\", \"BMI\"])\n",
        "    # balance data\n",
        "    grouped = data.groupby('TenYearCHD')\n",
        "    data = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
        "    # extract labels\n",
        "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
        "    data = data.drop(\"TenYearCHD\", 'columns')\n",
        "    # standardize data\n",
        "    data = (data - data.mean()) / data.std()\n",
        "    x = torch.tensor(data.values).float()\n",
        "    return split_train_test(x, y)\n",
        "\n",
        "# You can use whatever data you want without modification to the tutorial\n",
        "# x_train, y_train, x_test, y_test = random_data()\n",
        "x_train, y_train, x_test, y_test = heart_disease_data()\n",
        "\n",
        "print(\"############# Data summary #############\")\n",
        "print(f\"x_train has shape: {x_train.shape}\")\n",
        "print(f\"y_train has shape: {y_train.shape}\")\n",
        "print(f\"x_test has shape: {x_test.shape}\")\n",
        "print(f\"y_test has shape: {y_test.shape}\")\n",
        "print(\"#######################################\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Data summary #############\n",
            "x_train has shape: torch.Size([780, 9])\n",
            "y_train has shape: torch.Size([780, 1])\n",
            "x_test has shape: torch.Size([334, 9])\n",
            "y_test has shape: torch.Size([334, 1])\n",
            "#######################################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_66415/3852471796.py:25: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  data = data.drop(\"TenYearCHD\", 'columns')\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127212195
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a normal Logistic Regression Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "* Make a logistic model as simply a neural network with one linear layer and a sigmoid activation function\n",
        "* Train the model with `SGD` and `Binary Cross Entropy Loss` on the plaintext training dataset\n",
        "* Test the model on the plaintext test dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "class LR(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_features):\n",
        "        super(LR, self).__init__()\n",
        "        self.lr = torch.nn.Linear(n_features, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = torch.sigmoid(self.lr(x))\n",
        "        return out"
      ],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127545683
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "n_features = x_train.shape[1]\n",
        "model = LR(n_features)\n",
        "# use gradient descent with a learning_rate=1\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
        "# use Binary Cross Entropy Loss\n",
        "criterion = torch.nn.BCELoss()"
      ],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127573308
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# define the number of epochs for both plain and encrypted training\n",
        "EPOCHS = 5\n",
        "\n",
        "def train(model, optim, criterion, x, y, epochs=EPOCHS):\n",
        "    for e in range(1, epochs + 1):\n",
        "        optim.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        print(f\"Loss at epoch {e}: {loss.data}\")\n",
        "    return model\n",
        "\n",
        "model = train(model, optim, criterion, x_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epoch 1: 0.8504331707954407\n",
            "Loss at epoch 2: 0.6863384246826172\n",
            "Loss at epoch 3: 0.6358115077018738\n",
            "Loss at epoch 4: 0.6193529367446899\n",
            "Loss at epoch 5: 0.6124349236488342\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127587223
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "def accuracy(model, x, y):\n",
        "    out = model(x)\n",
        "    correct = torch.abs(y - out) < 0.5\n",
        "    return correct.float().mean()\n",
        "\n",
        "plain_accuracy = accuracy(model, x_test, y_test)\n",
        "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on plain test_set: 0.703592836856842\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632127626259
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is worth to remember that a high accuracy isn't our goal. \n",
        "We just want to see that training on encrypted data doesn't affect the final result, \n",
        "so we will be comparing accuracies over encrypted data against the plain_accuracy \n",
        "we got here."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encrypted Evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the logistic regression model with **plain parameters** (optionally encrypted parameters) on the **encrypted test set**.  \n",
        "Steps: \n",
        "* Create a TenSeal context and encrypt the test dataset \n",
        "* Create a model that can evaluate encrypted data, the model will get the weights from the previously trained LR model on plaintext training dataset\n",
        "* Inference: run the model on the encrypted test dataset\n",
        "* Decrypt the output, apply sigmoid on the decrypted data, calculate the accuracy, compare the accuracy when doing\n",
        "evaluation on encrypted data vs on plain data."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's make a tenseal context to encrypt the test dataset. Here we choose small and secure parameters that allow us to make a single multiplication. That's enough for evaluating a logistic regression model, however, we will see that we need larger parameters when doing training on encrypted data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "# parameters\n",
        "poly_mod_degree = 4096\n",
        "coeff_mod_bit_sizes = [40, 20, 40]\n",
        "# create TenSEALContext\n",
        "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "# scale of ciphertext to use\n",
        "ctx_eval.global_scale = 2 ** 20\n",
        "# this key is needed for doing dot-product operations\n",
        "ctx_eval.generate_galois_keys()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encrypt the whole test set before the evaluation:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "ic(len(x_test))\n",
        "t_start = time()\n",
        "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in x_test]\n",
        "t_end = time()\n",
        "ic(len(enc_x_test))\n",
        "print(f\"Encryption of the test-set took {int(t_end - t_start)} seconds\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| len(x_test): 334\n",
            "ic| len(enc_x_test): 334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the test-set took 0 seconds\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's a PyTorch-like LR model that can evaluate encrypted data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "class EncryptedLR:\n",
        "    \n",
        "    def __init__(self, torch_lr):\n",
        "        # TenSEAL processes lists and not torch tensors,\n",
        "        # so we take out the parameters from the PyTorch model\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        \n",
        "    def forward(self, enc_x):\n",
        "        # We don't need to perform sigmoid as this model\n",
        "        # will only be used for evaluation, and the label\n",
        "        # can be deduced without applying sigmoid\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        return enc_out\n",
        "    \n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n",
        "        \n",
        "    ################################################\n",
        "    ## You can use the functions below to pprint(erform ##\n",
        "    ## the evaluation with an encrypted model     ##\n",
        "    ################################################\n",
        "    \n",
        "    def encrypt(self, context):\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "        \n",
        "    def decrypt(self, context):\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "        \n",
        "\n",
        "eelr = EncryptedLR(model)"
      ],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632140533404
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you may have already noticed when we built the `EncryptedLR` class, we don't compute the sigmoid function on the encrypted output of the linear layer, simply because it's not needed, and computing sigmoid over encrypted data will increase the computation time and require larger encryption parameters. However, we will use sigmoid for the encrypted training part. We now proceed with the evaluation of the encrypted test set and compare the accuracy to the one on the plain test set."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "def encrypted_evaluation(model, enc_x_test, y_test):\n",
        "    t_start = time()\n",
        "    \n",
        "    correct = 0\n",
        "    for enc_x, y in zip(enc_x_test, y_test):\n",
        "        # encrypted evaluation\n",
        "        enc_out = model(enc_x)\n",
        "        # plain comparison\n",
        "        out = enc_out.decrypt()\n",
        "        out = torch.tensor(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        if torch.abs(out - y) < 0.5:\n",
        "            correct += 1\n",
        "    \n",
        "    t_end = time()\n",
        "    print(f\"Evaluated test_set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
        "    print(f\"Accuracy: {correct}/{len(x_test)} = {correct / len(x_test)}\")\n",
        "    return correct / len(x_test)\n",
        "    \n",
        "\n",
        "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n",
        "diff_accuracy = plain_accuracy - encrypted_accuracy\n",
        "print(f\"Difference between plain and encrypted accuracies: {diff_accuracy}\")\n",
        "if diff_accuracy < 0:\n",
        "    print(\"Oh! We got a better accuracy on the encrypted test-set! The noise was on our side...\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated test_set of 334 entries in 1 seconds\n",
            "Accuracy: 230/334 = 0.688622754491018\n",
            "Difference between plain and encrypted accuracies: 0.014970064163208008\n"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632141780363
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saw that evaluating on the encrypted test set doesn't affect the accuracy that much. I've even seen examples where the encrypted evaluation performs better."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training an Encrypted Logistic Regression Model on Encrypted Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part we learn to train a model on encrypted data.  \n",
        "Steps:\n",
        "* Make the TenSeal context and encrypt the training dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Theory"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss function  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's derive the binary cross entropy loss function:  \n",
        "First, the `sigmoid` function $\\sigma(z)$ is:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "  \\sigma(z) &= \\frac{1}{1+e^{-z}} \\\\\n",
        "  \\text{Cool property:}\\quad 1-\\sigma(z) &= \\frac{e^{-z}}{1+e^{-z}} = \\frac{1}{e^z+1} = \\sigma(-z) \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "A predictor for $y\\in\\{0,1\\}$ from $x$ is:\n",
        "$$\\hat{P}(y \\mid \\boldsymbol{x}, \\boldsymbol{\\theta}) = \\frac{1}{1+e^{-\\boldsymbol{\\theta} \\boldsymbol{x}}}$$\n",
        "The likelihood function to access the model performance is:\n",
        "$$L(\\theta) = \\prod_{i=1}^{m}\\hat{P}(y^{(i)} \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}),$$\n",
        "where $m$ is the number of training examples, $x^{(i)}$ is the training example $i^{th}$.  \n",
        "Appy negative log for both sides:\n",
        "$$\n",
        "-\\log (L(\\theta)) = -\\sum_{i=1}^{m}\\log (\\hat{P}(y^{(i)} \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}))\n",
        "$$\n",
        "Because logarithm is a strictly monotonic function, minimizing the negative log-likelihood will result in the same parameters $\\theta$ as when maximizing directly the likelihood function.  \n",
        "\n",
        "Now, because\n",
        "$$\n",
        "\\begin{equation*}\n",
        "  \\hat{P}(y^{(i)} \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}) =\n",
        "    \\begin{cases}\n",
        "      \\hat{P}(1 \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta})^1 &\\text{if} ~ y^{(i)}=1 \\\\\n",
        "      \\hat{P}(0 \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta})^{1-0} &\\text{if} ~ y^{(i)}=0\n",
        "    \\end{cases}       \n",
        "\\end{equation*}\n",
        "$$\n",
        "we can rewrite $\\hat{P}(y^{(i)} \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta})$ as \n",
        "$$\n",
        "\\hat{P}(y^{(i)} \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}) = \\hat{P}(1\\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta})^{y^{(i)}} * \\hat{P}(0 \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta})^{1-y^{(i)}}\n",
        "$$\n",
        "Assign $\\hat{P}(1 \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}) = \\hat{p} = \\hat{y}^{(i)}$ (we only need to predict the positive class), and as we also have \n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\hat{P}(0 \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}) \n",
        "&= 1 - \\hat{P}(1 \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}) \\\\\n",
        "\\Rightarrow \\hat{P}(0 \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}) &= 1 - \\hat{p}\n",
        "\\end{aligned}\n",
        "$$\n",
        "Therefore \n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\hat{P}(y^{(i)} \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta}) &\n",
        "= \\hat{P}(1\\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta})^{y^{(i)}} * \\hat{P}(0 \\vert \\boldsymbol{x^{(i)}}, \\boldsymbol{\\theta})^{1-y^{(i)}} \\\\\n",
        "&= \\hat{p}^{y^{(i)}} * (1-\\hat{p})^{1-y^{(i)}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "Inserting this into the negative log equation and normalizing by the number of examples, we can obtain the binary cross-entropy loss function\n",
        "$$\n",
        "\\begin{aligned}\n",
        "J(\\theta) \n",
        "&=  -\\frac{1}{m} \\sum_{i=1}^{m}y^{(i)}\\log \\hat{p} + (1-y^{(i)})\\log(1-\\hat{p}) \\\\\n",
        "&= -\\frac{1}{m} \\sum_{i=1}^{m}y^{(i)}\\log \\hat{y}^{(i)} + (1-y^{(i)})\\log(1-\\hat{y}^{(i)})\n",
        "\\end{aligned}\n",
        "$$\n",
        "Adding the regulazation term we will have the final loss function\n",
        "$$\n",
        "J(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)})] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j^2\n",
        "$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:  \n",
        "[Binary cross-entropy and logistic regression](https://towardsdatascience.com/binary-cross-entropy-and-logistic-regression-bf7098e75559)  \n",
        "[Where did the Binary Cross-Entropy Loss Function come from?](https://towardsdatascience.com/where-did-the-binary-cross-entropy-loss-function-come-from-ac3de349a715)  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating the gradients and parameters update"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "On doing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:  \n",
        "[Deriving the sigmoid derivative via chain and quotient rules](https://hausetutorials.netlify.app/posts/2019-12-01-neural-networks-deriving-the-sigmoid-derivative/)  \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sigmoid Approximation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we can't simply compute sigmoid on encrypted data, we need to approximate it using a low degree polynomial, the lower the degree the better, as we aim to perform as few multiplications as possible, to be able to use smaller parameters and thus optimize computation. This tutorial uses a degree 3 polynomial from https://eprint.iacr.org/2018/462.pdf, which approximates the sigmoid function in the range $[-5,5]$.\n",
        "\n",
        "$$\\sigma(x) = 0.5 + 0.197 x - 0.004 x^3$$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Homomorphic Encryption Parameters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the input data to the parameter update, a ciphertext will need a multiplicative depth of 6, 1 for the dot product operation, 2 for the sigmoid approximation, and 3 for the backprobagation phase (one is actually hidden in the `self._delta_w += enc_x * out_minus_y` operation in the `backward()` function of the neural network, which is multiplying a 1-sized vector with an n-sized one, which requires masking the first slot and replicating it n times in the first vector). With a scale of around 20 bits, we need 6 coefficients modulus with the same bit-size as the scale, plus the last coeffcient, which needs more bits, we are already out of the 4096 polynomial modulus degree (which requires < 109 total bit count of the coefficients modulus, if we consider 128-bit security), so we will use 8192. This will allow us to batch up to 4096 values in a single ciphertext, but we are far away from this limitation, so we shouldn't even think about it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's make a TenSeal context and encrypt the training dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "# parameters\n",
        "poly_mod_degree = 8192\n",
        "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
        "# create TenSEALContext\n",
        "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
        "ctx_training.global_scale = 2 ** 21\n",
        "ctx_training.generate_galois_keys()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "t_start = time()\n",
        "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
        "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
        "t_end = time()\n",
        "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption of the training_set took 15 seconds\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct the class for the neural network"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "class EncryptedLR2:\n",
        "    \n",
        "    def __init__(self, torch_lr):\n",
        "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
        "        self.bias = torch_lr.lr.bias.data.tolist()\n",
        "        # we accumulate gradients and counts the number of iterations\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid(enc_x):\n",
        "        # We use the polynomial approximation of degree 3\n",
        "        # sigmoid(x) = 0.5 + 0.197 * x - 0.004 * x^3\n",
        "        # from https://eprint.iacr.org/2018/462.pdf\n",
        "        # which fits the function pretty well in the range [-5,5]\n",
        "        # polyval is a tenseal vector's function\n",
        "        return enc_x.polyval([0.5, 0.197, 0, -0.004])  \n",
        "\n",
        "    def forward(self, enc_x):\n",
        "        enc_out = enc_x.dot(self.weight) + self.bias\n",
        "        enc_out = EncryptedLR2.sigmoid(enc_out)\n",
        "        return enc_out\n",
        "        \n",
        "    def backward(self, enc_x, enc_out, enc_y):\n",
        "        # calculate the gradients, not doing update yet\n",
        "        out_minus_y = (enc_out - enc_y)\n",
        "        self._delta_w += enc_x * out_minus_y\n",
        "        self._delta_b += out_minus_y\n",
        "        self._count += 1\n",
        "\n",
        "    def update_parameters(self):\n",
        "        if self._count == 0:\n",
        "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
        "        # update weights\n",
        "        # We use a small regularization term to keep the output\n",
        "        # of the linear layer in the range of the sigmoid approximation\n",
        "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.05\n",
        "        self.bias -= self._delta_b * (1 / self._count)\n",
        "        # reset gradient accumulators and iterations count\n",
        "        self._delta_w = 0\n",
        "        self._delta_b = 0\n",
        "        self._count = 0\n",
        "\n",
        "    def plain_accuracy(self, x_test, y_test):\n",
        "        # evaluate accuracy of the model on\n",
        "        # the plain (x_test, y_test) dataset\n",
        "        w = torch.tensor(self.weight)\n",
        "        b = torch.tensor(self.bias)\n",
        "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
        "        correct = torch.abs(y_test - out) < 0.5\n",
        "        return correct.float().mean()    \n",
        "    \n",
        "    def encrypt(self, context):\n",
        "        # Encrypt the weights and biases\n",
        "        self.weight = ts.ckks_vector(context, self.weight)\n",
        "        self.bias = ts.ckks_vector(context, self.bias)\n",
        "        \n",
        "    def decrypt(self):\n",
        "        # Decrypt the weights and biases\n",
        "        self.weight = self.weight.decrypt()\n",
        "        self.bias = self.bias.decrypt()\n",
        "        \n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)"
      ],
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1632148259418
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we study the distribution of `x.dot(weight) + bias` in both plain and encrypted domains. Making sure that it falls into the range $[-5,5]$, which is where our sigmoid approximation is good at, and we don't want to feed it data that is out of this range so that we don't get erroneous output, which can make our training behave unpredictably. But the weights will change during the training process, and we should try to keep them as small as possible while still learning. A technique often used with logistic regression, and we do exactly this (but serving another purpose which is *generalization*), is known as *regularization*, and you might already have spotted the additional term `self.weight * 0.05` in the `update_parameters()` function, which is the result of doing regularization.\n",
        "\n",
        "To recap, since our sigmoid approximation is only good in the range $[-5,5]$, we want to have all its inputs in that range. In order to do this, we need to keep our logistic regression parameters as small as possible, so we apply regularization.\n",
        "\n",
        "**Note:** Keeping the parameters small certainly reduces the magnitude of the output, but we can also get out of range if the data wasn't standardized. You may have spotted that we standardized the data with a mean of 0 and std of 1, this was both for better performance, as well as to keep the inputs to the sigmoid in the desired range."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "normal_dist = lambda x, mean, var: np.exp(- np.square(x - mean) / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
        "\n",
        "def plot_normal_dist(mean, var, rmin=-10, rmax=10):\n",
        "    x = np.arange(rmin, rmax, 0.01)\n",
        "    y = normal_dist(x, mean, var)\n",
        "    fig = plt.plot(x, y)\n",
        "    \n",
        "# plain distribution\n",
        "lr = LR(n_features)\n",
        "data = lr.lr(x_test)\n",
        "mean, var = map(float, [data.mean(), data.std() ** 2])\n",
        "plot_normal_dist(mean, var)\n",
        "print(\"Distribution on plain data:\")\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution on plain data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "# encrypted distribution\n",
        "def encrypted_out_distribution(eelr, enc_x_test):\n",
        "    w = eelr.weight\n",
        "    b = eelr.bias\n",
        "    data = []\n",
        "    for enc_x in enc_x_test:\n",
        "        enc_out = enc_x.dot(w) + b\n",
        "        data.append(enc_out.decrypt())\n",
        "    data = torch.tensor(data)\n",
        "    mean, var = map(float, [data.mean(), data.std() ** 2])\n",
        "    plot_normal_dist(mean, var)\n",
        "    print(\"Distribution on encrypted data:\")\n",
        "    plt.show()\n",
        "\n",
        "eelr = EncryptedLR(lr)\n",
        "eelr.encrypt(ctx_training)\n",
        "encrypted_out_distribution(eelr, enc_x_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution on plain data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution on encrypted data:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit ('SyftEnv': conda)"
    },
    "kernel_info": {
      "name": "syftenv"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "d8c1a441a5f9f7733d33e10332ba6605fc14f14734f8e602f9ed7877aacd3dd5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}